{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thicket and Extra-P: Thicket Tutorial\n",
    "\n",
    "Thicket is a python-based toolkit for Exploratory Data Analysis (EDA) of parallel performance data that enables performance optimization and understanding of applicationsâ€™ performance on supercomputers. It bridges the performance tool gap between being able to consider only a single instance of a simulation run (e.g., single platform, single measurement tool, or single scale) and finding actionable insights in multi-dimensional, multi-scale, multi-architecture, and multi-tool performance datasets.\n",
    "\n",
    "#### NOTE: An interactive version of this notebook is available in the Binder environment.\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/llnl/thicket-tutorial/develop)\n",
    "\n",
    "# Thicket Modeling Example\n",
    "\n",
    "This notebook provides an example for using Thicket's modeling feature. The modeling capability relies on _Extra-P_ - a tool for empirical performance modeling. It can perform N-parameter modeling with up to 3 parameters (N <= 3). The models follow a so-called _Performance Model Normal Form (PMNF)_ that expresses models as a summation of polynomial and logarithmic terms. One of the biggest advantages of this modeling method is that the produced models are human-readable and easily understandable.\n",
    "\n",
    "***\n",
    "\n",
    "## 1. Import Necessary Packages\n",
    "\n",
    "To explore the capabilities of thicket with Extra-P, we begin by importing necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "\n",
    "import thicket as th\n",
    "import hatchet as ht\n",
    "from thicket.model_extrap import ExtrapInterface\n",
    "from thicket.model_extrap import multi_display\n",
    "\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Dataset Paths and Names\n",
    "\n",
    "In this example, we use an MPI scaling study, profiled with Caliper, that has metadata about the runs. The data is also already aggregated, which means we can provide the data to Extra-P as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../data/lulesh/\"\n",
    "thicket = th.Thicket.from_caliperreader(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, the metadata table for this set of profiles contains a `jobsize` column, which provides the amount of cores used for each profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thicket.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. More Information on a Function\n",
    "***\n",
    "You can use the `help()` method within Python to see the information for a given object. You can do this by typing `help(object)`. \n",
    "This will allow you to see the arguments for the function, and what will be returned. An example is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ExtrapInterface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Models\n",
    "\n",
    "First, we instatiate an Extra-P interface to create performance models and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface = ExtrapInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create the performance models by passing the thicket object that contains the performance measurements to the `create_models()` function of the `ExtrapInterface`. In order to create the models the interface requires some more information. First, we need to provide the names of the parameters that should be considered for modeling, e.g., the `jobsize`. The `create_models()` function will grab this column from the metadata table to use as our parameter. We also sub-select some metrics, since this dataset has a lot of metrics (otherwise the modeling will take a long time to do all metrics). Finally, we provide a name for the model configuration that the function is going to create for us. Extra-P will internally use the provided name as a unique identifier for modeling experiments. This will come in handy when experimenting with different modeling parameters, metrics, and modeler configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface.create_models(thicket, \n",
    "                               parameters=[\n",
    "                                   \"jobsize\",\n",
    "                                ], \n",
    "                               metrics=[\n",
    "                                   \"Avg time/rank (exc)\",\n",
    "                                   ],\n",
    "                               model_name=\"config1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Multi-Parameter Models\n",
    "\n",
    "Extra-P support multi-parameter modeling. Consequently you can analyze multiple application parameters with Thicket and Extra-P. To create performance models considering multiple parameters simply provide them for the `parameters` variable of the `create_models()` function. The code below shows an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thicket_multi = th.Thicket.from_caliperreader(data)\n",
    "extrap_interface_multi = ExtrapInterface()\n",
    "extrap_interface_multi.create_models(thicket_multi, \n",
    "                               parameters=[\n",
    "                                   \"jobsize\",\n",
    "                                   \"problem_size\"\n",
    "                                ], \n",
    "                               metrics=[\n",
    "                                   \"Avg time/rank (exc)\",\n",
    "                                   ],\n",
    "                               model_name=\"config1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Models Dataframe\n",
    "\n",
    "The created performance models including some statistical quality control metrics such as the RSS (residual sum of squares) or the SMAPE (symmetric mean absolute percentage error) are stored in thicket's aggregated statistics table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thicket.statsframe.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Show the Models Dataframe with Embedded Plots\n",
    "\n",
    "(For every `node`, sub-selected `metric` combination)\n",
    "\n",
    "Besides the thicket object containing the models one can provide a variety of plotting options to the `to_html()` function that will change the displayed plots. One can for example select between displaying the mean, median, min, max measured metric values. Furthermore, one can display statistical values such as the RSS and SMAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", 1):\n",
    "    display(HTML(extrap_interface.to_html(thicket, show_mean=True, show_median=True, show_min_max=True, RSS=True, SMAPE=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Multi-Parameter Data\n",
    "\n",
    "To display multi-parameter models one can simply use the same functions as for single-parameter models. The method itself will figure out how many model parameters exist and choose the correct function to display your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", 1):\n",
    "    display(HTML(extrap_interface_multi.to_html(thicket_multi, show_mean=True, show_median=True, show_min_max=True, RSS=True, SMAPE=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying multiple models in one plot\n",
    "\n",
    "To display multiple models in one plot one case use the `multi_display()` function.\n",
    "\n",
    "We can for example filter the dataframe for all kernels that belong to MPI operations.\n",
    "We then take the models of specific kernels, e.g., the first two, and pass them into the `multi_display()` function.\n",
    "The `multi_display()` function then displays both models in the same plot. This works for models with multiple parameter as shown in the example below but also for models with only a single parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_objects = thicket_multi.statsframe.dataframe[\"Avg time/rank (exc)_extrap-model\"].filter(like=\"MPI_\")\n",
    "    \n",
    "models = []\n",
    "max = 2\n",
    "counter = 0\n",
    "for model in model_objects:\n",
    "    if counter < max:\n",
    "        models.append(model)\n",
    "    counter += 1\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = multi_display(models)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Query Specific Model\n",
    "\n",
    "The last node `{\"name\": \"MPI_Allreduce\", \"type\": \"function\"}`, has an interesting graph so we want to retrieve its model. This can be achieved by indexing the `models_df` DataFrame for our chosen node for the metric `Avg time/rank (exc)_extrap-model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = thicket.statsframe.dataframe.at[thicket.statsframe.dataframe.index[len(thicket.statsframe.dataframe.index)-1], \"Avg time/rank (exc)_extrap-model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the function of a model via the model object as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj.mdl.hypothesis.function.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Operations on a model\n",
    "\n",
    "To predict a metric value for a specific configuration of the chosen model parameters, we can evaluate the model like a function by simply providing the values of the chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj.eval(600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the model:\n",
    "\n",
    "It returns a _figure_ and an _axis_ objects. The axis object can be used to adjust the plot, i.e., change labels. The `display()` function features several optional input variables that change they way how the data is displayed. For example we can set the `RSS` (bool) value, that determines whether to display Extra-P RSS on the plot. Furthermore, we can show the min, max, mean, and median measured metric values again. Finally, we have the option to display an \"optimal\" scaling model. If one has an idea how the function should scale like, this expectation function can be enetered as shown in the example code below. The plot then shows the expected metric value compared to the created Extra-P model, ready for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = model_obj.display(show_mean=True, show_median=True, \n",
    "                            show_min_max=True, \n",
    "                            RSS=True, SMAPE=True, show_opt_scaling=True,\n",
    "                            opt_scaling_func=\"log2(p)**1\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is true when plotting the results of a multi-parameter model. An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj_multi = thicket_multi.statsframe.dataframe.at[thicket_multi.statsframe.dataframe.index[len(thicket_multi.statsframe.dataframe.index)-1], \"Avg time/rank (exc)_extrap-model\"]\n",
    "plt.clf()\n",
    "fig, ax = model_obj_multi.display(show_mean=True, show_median=True, \n",
    "                            show_min_max=True, \n",
    "                            RSS=True, SMAPE=True, show_opt_scaling=True,\n",
    "                            opt_scaling_func=\"q*log2(p)**1\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want an interactive matplotlib chart you can set `%matplotlib widget` in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Weak and strong scaling support\n",
    "\n",
    "Extra-P can model measurement data from weak and strong scaling experiments. The examples shown in the previous cells all used weak scaling. To create a model using data from a strong scaling experiment, Extra-P uses a workaround. Essentially it converts the data from the strong scaling experiment to a weak scaling experiment. As a consequence metric values, e.g., the runtime increases the larger the jobsize. This might me confusing at first as one would expect the runtime to decrease the larger the jobsize. When analyzing the scalability of the created models one has to think of it as a weak scaling experiment instead of strong scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strong = \"../data/lulesh_strong\"\n",
    "thicket_strong = th.Thicket.from_caliperreader(data_strong)\n",
    "extrap_interface_strong = ExtrapInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models for strong scaling measurements:\n",
    "\n",
    "To use this functionality we simply have to set the variable `calc_total_metrics=True` of the `create_models()` function. In addition we need to specify the scaling parameter of the performance experiment, which is usually the resource allocation, e.g., the number of MPI ranks. In this example the *jobsize* corresponds to the number of MPI ranks the application was executed with. Therefore, we set `scaling_parameter=\"jobsize\"` accordingly. Based on this information Extra-P multiplies the measured metric values with the number of MPI ranks, to convert the data from a weak into a strong scaling experiment. Though, this is only done for metrics that are measured per rank, e.g., the *Avg time/rank*. This conversion does not apply to metrics such as the *Total time* for which it would make no sense. If the `scaling` and `scaling_parameter` parameters of the `create_models()` function are not specified, the data will be automatically read as a weak scaling experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface_strong.create_models(thicket_strong, \n",
    "                                parameters=[\n",
    "                                   \"jobsize\",\n",
    "                                ], \n",
    "                               metrics=[\n",
    "                                   \"Avg time/rank\",\n",
    "                                   \"Total time\"\n",
    "                                   ],\n",
    "                               use_median=True,\n",
    "                               calc_total_metrics=True,\n",
    "                               scaling_parameter=\"jobsize\",\n",
    "                               model_name=\"config1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing a strong scaling experiment\n",
    "\n",
    "Subesequently, we can analyze the data as before. We can take a look at thicket's aggregated statistics table or show the models dataframe with the embedded plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thicket_strong.statsframe.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the models dataframe with the embedded plots, we see that models for the metrics *Avg time/rank, Total time*. are almost perfectly identical. This should be the case and indicates that the strong scaling data was correctly converted into a weak scaling experiment.\n",
    "\n",
    "In this case both metrics are showing redundant information as we intentionally measured the total time to highlight the conversion process. In reality the *Total time* might not be available as a metric. \n",
    "\n",
    "Subsequently, one can analyze and display the created models as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = thicket_strong.statsframe.dataframe.at[thicket_strong.statsframe.dataframe.index[0], \"Avg time/rank_extrap-model\"]\n",
    "plt.clf()\n",
    "fig, ax = model_obj.display(show_mean=True, show_median=True, \n",
    "                            show_min_max=True, RSS=True, \n",
    "                            AR2=True, show_opt_scaling=True,\n",
    "                            opt_scaling_func=\"p**1*log2(p)**1\")\n",
    "ax.legend(loc=1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extra-P Modeler Configuration Support\n",
    "\n",
    "Extra-P feastures several modeling techniques that are used to create performance models. Depending on the modeling problem at hand one might perform better than another. More information about this can be found in the Extra-P documentation at: [Extra-P](https://github.com/extra-p/extrap).\n",
    "\n",
    "To show the available modelers from Extra-P that can be used for modeling one can run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../data/lulesh/\"\n",
    "thicket = th.Thicket.from_caliperreader(data)\n",
    "extrap_interface = ExtrapInterface()\n",
    "extrap_interface.print_modelers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, each modeler has a specific set of configuration options that determine how the models are created and for example define the search space for the models.\n",
    "To query these options for a specific modeler one can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface.print_modeler_options(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to explore Extra-P's modeling capabilities you can try to use a different modeler and see the difference in models it will return. To change the model generator Extra-P will use specify the name of the modeler as shown below. Here we use the refining modeler instead, which automatically adjusts the search space of the models for the user. Therefore, there is no need to specify the exponents Extra-P should use for modeling.\n",
    "Furthermore, this example shows how to create models for several parameters and metrics.\n",
    "To create models for several parameters or metrics simply provide them as a list of string values.\n",
    "\n",
    "There are several additional parameters to this method. For example, one can use the parameter `use_median=True` to switch between using the median and mean values of the measured performance metrics values of a measurement point (application configuration) for modeling.\n",
    "\n",
    "The `add_stats=True` parameter let's you specify if you want to have Extra-P's statistical values extended to the dataframe object of thicket. These values are internally used by Extra-P to decide which of the found hypotheses will be the best model for a certain node/kernel and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface.create_models(thicket, \n",
    "                               parameters=[\n",
    "                                   \"jobsize\"\n",
    "                                ], \n",
    "                               metrics=[\n",
    "                                   \"Avg time/rank (exc)\",\n",
    "                                   \"Avg time/rank\"\n",
    "                                   ], \n",
    "                               use_median=True,\n",
    "                               modeler=\"refining\",\n",
    "                               model_name=\"config1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For advanced users, you can specific which options Extra-P should use when creating the models. This will influence the type of models you will get.\n",
    "Define the modeler options that you want to use for modeling in the form of a dictonary and pass them to the create_models() function of the extrap interface.\n",
    "Use the previously shown `print_modeler_options(\"default\")` function to display which options are available for a specific modeler.\n",
    "Make sure that the options you are setting are available for the modeler that you specified via `modeler=\"\"`. If not the Extra-P interface will let you know and continue using the default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler_options = {'allow_log_terms': True,\n",
    "                   'use_crossvalidation': True,\n",
    "                   'compare_with_RSS': False,\n",
    "                   'poly_exponents': \"0,1,2,3,4,5\",\n",
    "                   'log_exponents': \"0,1,2\",\n",
    "                  }\n",
    "\n",
    "extrap_interface.create_models(thicket, \n",
    "                               parameters=[\n",
    "                                   \"jobsize\"\n",
    "                                ], \n",
    "                               metrics=[\n",
    "                                   \"Avg time/rank (exc)\",\n",
    "                                   ], \n",
    "                               use_median=True,\n",
    "                               modeler=\"default\",\n",
    "                               model_name=\"config2\",\n",
    "                               modeler_options=modeler_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then one can display the models as before using the following code. Now the datframe has a multi-column index, using the name of the specified `model_name` parameter of the `create_models` function.\n",
    "Take a look how one of the configurations has performance models for two metrics and the other one has only one. It is also possible to consider differen model parameters for each modeling configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thicket.statsframe.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the multi-column index one can also simply only analyze one of the configurations used for modeling with Extra-P as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thicket.statsframe.dataframe[\"config2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for displaying the models. By specifying the name of the configuration we can access only the model configuration we want to analyse using the multi-column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = thicket.statsframe.dataframe[\"config2\"].at[thicket.statsframe.dataframe.index[len(thicket.statsframe.dataframe.index)-1], \"Avg time/rank (exc)_extrap-model\"]\n",
    "plt.clf()\n",
    "fig, ax = model_obj.display(show_mean=True, show_median=True, \n",
    "                            show_min_max=True, RSS=True, \n",
    "                            AR2=True, show_opt_scaling=True,\n",
    "                            opt_scaling_func=\"log2(p)**1\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeler Configuration for Multi-Parameter Models\n",
    "\n",
    "For multi-parameter models more modeler configuration options are available. First, one can query the options of our multi-parameter modeler as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface.print_modeler_options(\"multi-parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multi-parameter modeling scenario one first sets the configuration parameters of the multi-parameter modeler, then the one of the single-parameter modeler used by the multi-parameter modeler.\n",
    "\n",
    "The options are specified in a dictionary as key value pairs. The code below shows an example. To set the single-parameter modeler used by the multi-parameter modeler one has to set `'#single_parameter_modeler': \"default\"` in this dictionary. To set the options for the single-parameter modeler one has to set `'#single_parameter_options'` and provide a dictionary for the single-parameter modeler options as the value, e.g., `{'poly_exponents': \"0,1,2,3,4,5\", 'log_exponents': \"0,1,2\"}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler_options = {'compare_with_RSS': False,\n",
    "                   'allow_combinations_of_sums_and_products': True,\n",
    "                   '#single_parameter_modeler': \"default\",\n",
    "                   '#single_parameter_options': {'poly_exponents': \"0,1,2,3,4,5\",\n",
    "                   'log_exponents': \"0,1,2\"},\n",
    "                  }\n",
    "\n",
    "extrap_interface.create_models(thicket, \n",
    "                               parameters=[\n",
    "                                   \"jobsize\",\n",
    "                                   \"problem_size\"\n",
    "                                ], \n",
    "                               metrics=[\n",
    "                                   \"Avg time/rank (exc)\"\n",
    "                                   ], \n",
    "                               use_median=True,\n",
    "                               modeler=\"multi-parameter\",\n",
    "                               model_name=\"config3\",\n",
    "                               modeler_options=modeler_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Aggregation of Kernels in a Thicket Dataframe\n",
    "\n",
    "Sometimes it might be of interest to aggregate a certain set of kernels together and create one performance function for all of them using Extra-P.\n",
    "\n",
    "To do so the `ExtrapInterface` class provides a method `produce_aggregated_model()` that takes a thicket as an input. The `produce_aggregated_model()` function will autmatically aggregate all kernels in this thicket by their measured metric values aved in the ModelWrapper objects of each kernel. Then a new Extra-P experiment is created that contains only one kernel, the new aggregated one. Subsequently, a new pandas DataFrame is returned that contains the aggregated kernel Model and so on. The code below provides an example for a kernel aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = extrap_interface_multi.produce_aggregated_model(thicket_multi)\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then visualize the aggregated performance model and compare it to the expected behavior or manipulate the plot as wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = agg_df.at[agg_df.index[0], \"Avg time/rank (exc)_extrap-model\"]\n",
    "plt.clf()\n",
    "fig, ax = model_obj.display(show_mean=True, show_median=True, \n",
    "                            show_min_max=True, RSS=True, \n",
    "                            AR2=True)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Complexity Analysis with Extra-P\n",
    "\n",
    "Using the functionalities of Extra-P and Thicket one can easily perform a complexity analysis of the scaling behavior of all nodes in a Thicket.\n",
    "Therefore, one can use the `complexity_statsframe()` function, which requires only the thicket and the evaluation target as an input. With `eval_targets=[[512]]` one specifies the target scale of the values of the considered model parameters that will be used for the evaluation of the models scaling complexity. The `complexity_statsframe()` function will add three columns to the dataframe: model complexity, the model coefficient, and the growth rank. The column names of these three columns are indexed by the specified evaluation target. The model complexity is the term of the model contributes the most to the asymptotic scaling behavior of the model for the specified evaluation target. The model coefficient is the coefficient of this model term. The growth rank is a ranking of all nodes scaling behavior compared with each other.\n",
    "\n",
    "Furthermore, one can specify several evaluation targets such as (the three columns described above will be added for each evaluation target):\n",
    "\n",
    "```\n",
    "eval_targets=[[512]]\n",
    "eval_targets=[[512],[1024],...]\n",
    "```\n",
    "\n",
    "For multiple parameters:\n",
    "\n",
    "```\n",
    "eval_targets=[[512,60]]\n",
    "eval_targets=[[512,60],[1024,70],...]\n",
    "```\n",
    "\n",
    "Subsequently, we can for example sort the nodes by their growth ranks and display the dataframe. This provides some insight in which node has the fastest growing metric value at the target scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface_multi.complexity_statsframe(thicket_multi, eval_targets=[[512,60]])\n",
    "complexity_df = thicket_multi.statsframe.dataframe\n",
    "complexity_df = complexity_df.sort_values(by=[\"Avg time/rank (exc)_extrap-model_growth_rank_(512,60)\"])\n",
    "complexity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pipe this information into hatchet and visualize it as a tree using the following code. In the example below each hatchet node shown the metric value and the model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.median(thicket_multi, columns=[\"Avg time/rank (exc)\"])\n",
    "\n",
    "print(str(thicket_multi.statsframe.tree(\n",
    "    metric_column='Avg time/rank (exc)_median', \n",
    "    annotation_column=\"Avg time/rank (exc)_extrap-model_complexity_(512,60)\", \n",
    "    colormap=\"RdYlGn\", \n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also replace the metric value with the calculated growth rank of each node as shown in the example below. Note that the color coding of the tree corresponds to the found model complexity, metric values, and growth ranks. The legend indicates the color coding and their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.median(thicket_multi, columns=[\"Avg time/rank (exc)\"])\n",
    "\n",
    "print(str(thicket_multi.statsframe.tree(\n",
    "    metric_column=\"Avg time/rank (exc)_extrap-model_growth_rank_(512,60)\", \n",
    "    annotation_column=\"Avg time/rank (exc)_extrap-model_complexity_(512,60)\", \n",
    "    colormap=\"RdYlGn\", \n",
    "    invert_colormap=True,\n",
    "    )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Configuration Analysis\n",
    "\n",
    "The same also works when the dataframe contains multiple Extra-P modeler configurations. However, make sure that when, e.g. sorting the dataframe by growth ranks, you also index the modeler configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thicket.statsframe.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extrap_interface.complexity_statsframe(thicket, eval_targets=[[512]])\n",
    "complexity_df = thicket.statsframe.dataframe\n",
    "complexity_df[\"config1\"].sort_values(by=[\"Avg time/rank_extrap-model_growth_rank_(512)\"])\n",
    "complexity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly one has to provide the modeler config name `modeler_config=\"config1\"` when creating a hatchet tree, so that the tree function know where to take the data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.median(thicket, columns=[\"Avg time/rank\"])\n",
    "\n",
    "print(thicket.statsframe.tree(\n",
    "    metric_column='Avg time/rank_median', \n",
    "    annotation_column=\"Avg time/rank_extrap-model_complexity_(512)\", \n",
    "    colormap=\"RdYlGn\",\n",
    "    modeler_config=\"config1\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Componentizing a Statsframe for Complexity analysis\n",
    "\n",
    "Another way to analyze the complexity of the kernels in a thicket is by componentizing the models created by Extra-P and analyzing the complexities found in all kernels.\n",
    "Therefore, the `ExtrapInterface` features a function `componentize_statsframe()` that takes a thicket as an input and then componentizes the extra-p model for each kernel into its different parts, meaning into its terms, e.g., `c, log2(p), p*log2(p), ...`. The code below provides an example for this type of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrap_interface.componentize_statsframe(thicket)\n",
    "xp_comp_df = thicket.statsframe.dataframe\n",
    "xp_comp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9b2a95c73c2c3cbd2385f2b17bb401a2882e839041a509387bd5d08c5b62925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
